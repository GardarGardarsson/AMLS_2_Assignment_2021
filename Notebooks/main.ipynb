{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aware-anthony",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "*To [Table of Contents](#toc)*\n",
    "# Image Super Resolution\n",
    "## Applied Machine Learning Systems 2\n",
    "### University College London\n",
    "#### Department of Electronic and Electrical Engineering\n",
    "**Student Number:** $20167036$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-marks",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/squirrels.png\" alt=\"Drawing\" style=\"height: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-commonwealth",
   "metadata": {},
   "source": [
    "This project focuses on generating *Super Resolution* (SR) images from *Low Resolution* (LR) ones using deep learning techniques. <br>\n",
    "More specifically, the project aims at developing and evaluating deep learning models of various architectures for solving the [NTIRE2017 challenge](https://data.vision.ee.ethz.ch/cvl/ntire17/#challenge).\n",
    "\n",
    "The datasets used for training and evaluating the models may be accessed from the [DIV2K Dataset Website](https://data.vision.ee.ethz.ch/cvl/DIV2K/) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-alpha",
   "metadata": {},
   "source": [
    "<a id='toc'></a>\n",
    "## Table of Contents:\n",
    "0. [Introduction](#intro)\n",
    "1. [Loading Data](#load) \n",
    "2. [Construct Models](#construct) \n",
    "3. [Model Training](#training)\n",
    "4. [Performance Evaluation](#evaluate)\n",
    "5. [Credits](#credits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-balloon",
   "metadata": {},
   "source": [
    "---\n",
    "Things to try: \n",
    "---\n",
    "---\n",
    "1. Dong et al. 5-1-3-3-3-3-1-9, PReLUs **Note!** PReLUs in middle, mapping layer (?) ✅\n",
    "---\n",
    "2. Dong et al. 5-1-3-1-9, PReLUs (note, no PReLUs in middle, mapping layer, assume 1 x (3 x 3) layer of depth 4 x 12 <br> This can't be right to be fair - the middle layers are called non-linear mapping and it's explicitly stated that he's trying to add non-linearity so must be activating ❌\n",
    "---\n",
    "3. Ablation 1. 5-1-3-3-3-3-1-4, PReLUs, i.e. non-overlapping deconvolutional layer scale = stride = kernel <br> **Note!** I've gotta specifically code the patch sizes for the `x3` case, make divisible by 3. Maybe just floor the 64 / scale operation, so it would be: <br>\n",
    "Training patch size<br>\n",
    "x4: 64 / 4 = 16 <br>\n",
    "x3: 64 / 3 = 21 <br>\n",
    "x3: 64 / 2 = 32   <br> \n",
    "✅ Yielded worse performance, -1 db and -0.05 SSIM\n",
    "---\n",
    "4. Ablation 2. 4-1-3-3-3-3-1-4, PReLUs, i.e. have kernel size match patch size in input layers<br>\n",
    "✅ Much worse, grayscale outputs\n",
    "---\n",
    "5. Ablation 3. 3-1-3-3-1-4, PReLUs, i.e. start shrinking mapping layer, middle section\n",
    "---\n",
    "6. Tuning batch size\n",
    "---\n",
    "7. PReLU -> ReLU (?)\n",
    "---\n",
    "8. Weight initialisation (?)\n",
    "✅ Has absolutely everything to say!\n",
    "---\n",
    "9. Bias initialisation (?)\n",
    "---\n",
    "10. L1 Loss !!!\n",
    "✅ Worse\n",
    "---\n",
    "11. Skip connection (?) Global (?)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-office",
   "metadata": {},
   "source": [
    "<a id='load'></a>\n",
    "*Back to [Table of Contents](#toc)*\n",
    "<img src=\"./imgs/load.png\" alt=\"Drawing\" style=\"height: 80px;\"/>\n",
    "# 1. Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-galaxy",
   "metadata": {},
   "source": [
    "Set directory (Notebooks are not hosted in base directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "soviet-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-jewelry",
   "metadata": {},
   "source": [
    "Configure the problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "modular-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modules import user_interface as ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pregnant-wrapping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================\n",
      "             D I V 2 K   -   S U P E R   R E S O L U T I O N              \n",
      "==========================================================================\n",
      "\n",
      "\n",
      "Choose track:\n",
      "-------------\n",
      "1. Bicubic\n",
      "2. Unknown\n",
      "Select by entering number and hit 'RETURN': 2\n",
      "\n",
      "\n",
      "Choose scaling factor:\n",
      "----------------------\n",
      "1. Factor x2\n",
      "2. Factor x3\n",
      "3. Factor x4\n",
      "Select by entering number and hit 'RETURN': 3\n",
      "\n",
      "==========================================================================\n",
      "You have chosen the unknown degradation problem track with X4 downscaling.\n"
     ]
    }
   ],
   "source": [
    "### Print a welcome message\n",
    "print('='*74)\n",
    "greeting = 'D I V 2 K   -   S U P E R   R E S O L U T I O N'\n",
    "print(greeting.center(74))\n",
    "print('='*74)\n",
    "\n",
    "# Allow user to select problem track and scaling factor\n",
    "track  = ui.selection_menu('Choose track:', {'1':'Bicubic', \n",
    "                                             '2':'Unknown'})\n",
    "\n",
    "scale = ui.selection_menu('Choose scaling factor:', {'1' : 'Factor x2',\n",
    "                                                     '2' : 'Factor x3',\n",
    "                                                     '3' : 'Factor x4'}) \n",
    "\n",
    "# Parameterise the problem, use the configuration options to generate variables that can be used to navigate directories etc.\n",
    "if track is 1: \n",
    "    track = 'bicubic'\n",
    "else: \n",
    "    track = 'unknown'\n",
    "\n",
    "# Keep a numeric and string version of the scaling factor, strings for navigating directories, numeric for possibly scaling patch sizes etc\n",
    "if scale is 1: \n",
    "    scale     =  2\n",
    "    scale_str = 'X2'\n",
    "elif scale is 2: \n",
    "    scale     =  3\n",
    "    scale_str = 'X3'\n",
    "else: \n",
    "    scale     =  4\n",
    "    scale_str = 'X4'\n",
    "\n",
    "# Make user aware of selection\n",
    "prompt = 'You have chosen the ' + track + ' degradation problem track with ' + scale_str + ' downscaling.'\n",
    "print('\\n'+'='*len(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-twenty",
   "metadata": {},
   "source": [
    "### Instantiate datahandler\n",
    "This project uses [idealo's datahandler from GitHub](https://idealo.github.io/image-super-resolution/), that generates patches on the fly from a directory, augments them, and limit's how flat (detail-scarce) the cropped patches can be. Further explanation on the workings of the datahandler are provided in the report and the project notebook, `project_notebook.ipynb`, where I was developing my solution and getting acquainted with using the datahandler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "million-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISR.utils import datahandler as ISR_dh\n",
    "\n",
    "# Define parameters for the training task, let's use 48x48 patches for the x2 downscaled images\n",
    "lr_patch_size = int(128 / scale)  # Note! Patch sizes should probably be divided by scale factor\n",
    "batch_size    = 4                # Hyper parameter\n",
    "\n",
    "# We now create a datahandler for the training, and point it to the location of the LR and HR images\n",
    "datahandler = ISR_dh.DataHandler(lr_dir = './Datasets/DIV2K_train_LR_' + track + '/'+ scale_str + '/',\n",
    "                                 hr_dir = './Datasets/DIV2K_train_HR/',\n",
    "                                 patch_size = lr_patch_size, \n",
    "                                 scale      = scale,\n",
    "                                 n_validation_samples = 40)\n",
    "\n",
    "# Generate a validation set\n",
    "validation_set = datahandler.get_validation_set(batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-defensive",
   "metadata": {},
   "source": [
    "<a id='construct'></a>\n",
    "*Back to [Table of Contents](#toc)*\n",
    "<img src=\"./imgs/construction.png\" alt=\"Drawing\" style=\"height: 75px;\"/>\n",
    "# 2. Construct Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-person",
   "metadata": {},
   "source": [
    "I'll now define a couple of different model architectures, with varying:\n",
    "- Numbers of convolutional layers\n",
    "- Filter layer depths\n",
    "- Kernel sizes\n",
    "- Stride "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "verbal-conjunction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add a custom name affix to model: _Unknown_x4\n"
     ]
    }
   ],
   "source": [
    "custom_name = str(input(\"Add a custom name affix to model: \"))\n",
    "\n",
    "lr_scheduler   = {'initial_value'   : 1e-4 , \n",
    "                  'decay_factor'    : 0.9  , \n",
    "                  'minimum'         : 1e-7 , \n",
    "                  'update_interval' : 10    }\n",
    "\n",
    "adam_optimiser = {'beta1'   : 0.9   , \n",
    "                  'beta2'   : 0.999 , \n",
    "                  'epsilon' : 1e-8   }\n",
    "\n",
    "parameters  = {# Model Structure\n",
    "               'conv_layers'         : 7, \n",
    "               'conv_filters'        : [56, 16, 16, 16, 16, 16, 56],\n",
    "               'conv_kernel_sizes'   : [(5,5),(1,1),(3,3),(3,3),(3,3),(3,3),(1,1)],\n",
    "               'conv_strides'        : [(1,1),(1,1),(1,1),(1,1),(1,1),(1,1),(1,1)],\n",
    "               'deconv_layers'       : 1, \n",
    "               'deconv_filters'      : [3],\n",
    "               'deconv_kernel_sizes' : [(2*scale,2*scale)],\n",
    "               'deconv_strides'      : [(scale,scale)],\n",
    "               \n",
    "               # Optimiser settings\n",
    "               'lr_scheduler'        : lr_scheduler, \n",
    "               'adam_optimiser'      : adam_optimiser,\n",
    "               \n",
    "               # Affix for model name\n",
    "               'name_affix'          : custom_name} # The stride of the deconvolutional layer decides the scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-prescription",
   "metadata": {},
   "source": [
    "Now, I'll populate a list of models with the parameters from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "roman-chemical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, None, None, 56)    4256      \n",
      "_________________________________________________________________\n",
      "p_re_lu (PReLU)              (None, None, None, 56)    56        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, None, None, 16)    912       \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, None, None, 16)    16        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, None, None, 16)    2320      \n",
      "_________________________________________________________________\n",
      "p_re_lu_2 (PReLU)            (None, None, None, 16)    16        \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, None, None, 16)    2320      \n",
      "_________________________________________________________________\n",
      "p_re_lu_3 (PReLU)            (None, None, None, 16)    16        \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, None, None, 16)    2320      \n",
      "_________________________________________________________________\n",
      "p_re_lu_4 (PReLU)            (None, None, None, 16)    16        \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, None, None, 16)    2320      \n",
      "_________________________________________________________________\n",
      "p_re_lu_5 (PReLU)            (None, None, None, 16)    16        \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, None, None, 56)    952       \n",
      "_________________________________________________________________\n",
      "p_re_lu_6 (PReLU)            (None, None, None, 56)    56        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, None, None, 3)     10755     \n",
      "=================================================================\n",
      "Total params: 26,347\n",
      "Trainable params: 26,347\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from Modules import model as m\n",
    "\n",
    "model = m.SRCNN(**parameters)\n",
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-arctic",
   "metadata": {},
   "source": [
    "<a id='training'></a>\n",
    "*Back to [Table of Contents](#toc)*\n",
    "<img src=\"./imgs/training.png\" alt=\"Drawing\" style=\"height: 90px;\"/>\n",
    "# 3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-meaning",
   "metadata": {},
   "source": [
    "Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "opponent-finger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load stored model weights (y/n) ? n\n"
     ]
    }
   ],
   "source": [
    "if ui.yes_no_menu('Load stored model weights (y/n) ? '):\n",
    "    model.loadWeights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-forum",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model (y/n) ? y\n",
      "Number of epochs to run: 30\n",
      "Training: \n",
      "Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4\n",
      "------------------------------------------------------------\n",
      "            ... Initiating Training Session ...             \n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "                    E P O C H   1/30                    \n",
      "------------------------------------------------------------\n",
      " Runtime                   ==> 166.97866892814636s\n",
      " Learning rate             ==>     0.0001\n",
      " train_loss                ==> 0.03299858048558235\n",
      " train_psnr                ==> 14.884376525878906\n",
      " train_ssim                ==> 0.45810142159461975\n",
      " val_loss                  ==> 0.021865021961275488\n",
      " val_psnr                  ==> 17.776477813720703\n",
      " val_ssim                  ==> 0.5905104875564575\n",
      "Model weights saved to: ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "Best model weights w/ val loss 0.021865 saved to ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "------------------------------------------------------------\n",
      "                    E P O C H   2/30                    \n",
      "------------------------------------------------------------\n",
      " Runtime                   ==> 162.4605278968811s\n",
      " Learning rate             ==>     0.0001\n",
      " train_loss                ==> 0.017768390476703644\n",
      " train_psnr                ==> 17.65723419189453\n",
      " train_ssim                ==> 0.4735538363456726\n",
      " val_loss                  ==> 0.013813714287243784\n",
      " val_psnr                  ==> 20.131593704223633\n",
      " val_ssim                  ==> 0.6313654184341431\n",
      "Model weights saved to: ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "Best model weights w/ val loss 0.013814 saved to ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "------------------------------------------------------------\n",
      "                    E P O C H   3/30                    \n",
      "------------------------------------------------------------\n",
      " Runtime                   ==> 166.21738696098328s\n",
      " Learning rate             ==>     0.0001\n",
      " train_loss                ==> 0.01507566124200821\n",
      " train_psnr                ==> 18.792936325073242\n",
      " train_ssim                ==> 0.6696678400039673\n",
      " val_loss                  ==> 0.01205742247402668\n",
      " val_psnr                  ==> 20.912397384643555\n",
      " val_ssim                  ==> 0.6536216735839844\n",
      "Model weights saved to: ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "Best model weights w/ val loss 0.012057 saved to ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "------------------------------------------------------------\n",
      "                    E P O C H   4/30                    \n",
      "------------------------------------------------------------\n",
      " Runtime                   ==> 168.01854467391968s\n",
      " Learning rate             ==>     0.0001\n",
      " train_loss                ==> 0.013010005466639996\n",
      " train_psnr                ==> 19.066713333129883\n",
      " train_ssim                ==> 0.739596962928772\n",
      " val_loss                  ==> 0.011482354326290078\n",
      " val_psnr                  ==> 21.175161361694336\n",
      " val_ssim                  ==> 0.6669477224349976\n",
      "Model weights saved to: ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "Best model weights w/ val loss 0.011482 saved to ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "------------------------------------------------------------\n",
      "                    E P O C H   5/30                    \n",
      "------------------------------------------------------------\n",
      " Runtime                   ==> 161.03639721870422s\n",
      " Learning rate             ==>     0.0001\n",
      " train_loss                ==> 0.029536638408899307\n",
      " train_psnr                ==> 15.57336711883545\n",
      " train_ssim                ==> 0.5609253644943237\n",
      " val_loss                  ==> 0.01096506865869742\n",
      " val_psnr                  ==> 21.435266494750977\n",
      " val_ssim                  ==> 0.6766555905342102\n",
      "Model weights saved to: ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "Best model weights w/ val loss 0.010965 saved to ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "------------------------------------------------------------\n",
      "                    E P O C H   6/30                    \n",
      "------------------------------------------------------------\n",
      " Runtime                   ==> 167.87652707099915s\n",
      " Learning rate             ==>     0.0001\n",
      " train_loss                ==> 0.009365469217300415\n",
      " train_psnr                ==> 20.52094268798828\n",
      " train_ssim                ==> 0.7416054010391235\n",
      " val_loss                  ==> 0.010745955040329136\n",
      " val_psnr                  ==> 21.70838165283203\n",
      " val_ssim                  ==> 0.6820262670516968\n",
      "Model weights saved to: ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "Best model weights w/ val loss 0.010746 saved to ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "------------------------------------------------------------\n",
      "                    E P O C H   7/30                    \n",
      "------------------------------------------------------------\n",
      " Runtime                   ==> 167.42589116096497s\n",
      " Learning rate             ==>     0.0001\n",
      " train_loss                ==> 0.02220981754362583\n",
      " train_psnr                ==> 16.71575164794922\n",
      " train_ssim                ==> 0.4722520709037781\n",
      " val_loss                  ==> 0.010651854082243516\n",
      " val_psnr                  ==> 21.709693908691406\n",
      " val_ssim                  ==> 0.684518575668335\n",
      "Model weights saved to: ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "Best model weights w/ val loss 0.010652 saved to ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "------------------------------------------------------------\n",
      "                    E P O C H   8/30                    \n",
      "------------------------------------------------------------\n",
      " Runtime                   ==> 178.50882506370544s\n",
      " Learning rate             ==>     0.0001\n",
      " train_loss                ==> 0.009376123547554016\n",
      " train_psnr                ==> 20.311025619506836\n",
      " train_ssim                ==> 0.6867969036102295\n",
      " val_loss                  ==> 0.010227513255085797\n",
      " val_psnr                  ==> 22.061504364013672\n",
      " val_ssim                  ==> 0.6856257319450378\n",
      "Model weights saved to: ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "Best model weights w/ val loss 0.010228 saved to ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "                    E P O C H   9/30                    \n",
      "------------------------------------------------------------\n",
      " Runtime                   ==> 159.2905797958374s\n",
      " Learning rate             ==>     0.0001\n",
      " train_loss                ==> 0.02089763805270195\n",
      " train_psnr                ==> 16.832239151000977\n",
      " train_ssim                ==> 0.4901773929595947\n",
      " val_loss                  ==> 0.010016024045762606\n",
      " val_psnr                  ==> 22.22151756286621\n",
      " val_ssim                  ==> 0.6913560628890991\n",
      "Model weights saved to: ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "Best model weights w/ val loss 0.010016 saved to ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "------------------------------------------------------------\n",
      "                    E P O C H   10/30                    \n",
      "------------------------------------------------------------\n",
      " Runtime                   ==> 180.39546012878418s\n",
      " Learning rate             ==>     0.0001\n",
      " train_loss                ==> 0.012503274716436863\n",
      " train_psnr                ==> 20.128814697265625\n",
      " train_ssim                ==> 0.5814690589904785\n",
      " val_loss                  ==> 0.009744726557983086\n",
      " val_psnr                  ==> 22.269634246826172\n",
      " val_ssim                  ==> 0.6919519901275635\n",
      "Model weights saved to: ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "Best model weights w/ val loss 0.009745 saved to ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "------------------------------------------------------------\n",
      "                    E P O C H   11/30                    \n",
      "------------------------------------------------------------\n",
      " Runtime                   ==> 162.5400722026825s\n",
      " Learning rate             ==>      9e-05\n",
      " train_loss                ==> 0.010700499638915062\n",
      " train_psnr                ==> 19.887033462524414\n",
      " train_ssim                ==> 0.6339057683944702\n",
      " val_loss                  ==> 0.009268408600473777\n",
      " val_psnr                  ==> 22.596899032592773\n",
      " val_ssim                  ==> 0.6950544118881226\n",
      "Model weights saved to: ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "Best model weights w/ val loss 0.009268 saved to ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "------------------------------------------------------------\n",
      "                    E P O C H   12/30                    \n",
      "------------------------------------------------------------\n",
      " Runtime                   ==> 166.3755919933319s\n",
      " Learning rate             ==>      9e-05\n",
      " train_loss                ==> 0.00809841975569725\n",
      " train_psnr                ==> 21.92559814453125\n",
      " train_ssim                ==> 0.7474582195281982\n",
      " val_loss                  ==> 0.00900671055278508\n",
      " val_psnr                  ==> 22.86907196044922\n",
      " val_ssim                  ==> 0.6968507170677185\n",
      "Model weights saved to: ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "Best model weights w/ val loss 0.009007 saved to ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "------------------------------------------------------------\n",
      "                    E P O C H   13/30                    \n",
      "------------------------------------------------------------\n",
      " Runtime                   ==> 162.14516186714172s\n",
      " Learning rate             ==>      9e-05\n",
      " train_loss                ==> 0.013922387734055519\n",
      " train_psnr                ==> 19.02576446533203\n",
      " train_ssim                ==> 0.6718233823776245\n",
      " val_loss                  ==> 0.008923977776430548\n",
      " val_psnr                  ==> 22.949810028076172\n",
      " val_ssim                  ==> 0.699478268623352\n",
      "Model weights saved to: ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "Best model weights w/ val loss 0.008924 saved to ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "------------------------------------------------------------\n",
      "                    E P O C H   14/30                    \n",
      "------------------------------------------------------------\n",
      " Runtime                   ==> 162.1557698249817s\n",
      " Learning rate             ==>      9e-05\n",
      " train_loss                ==> 0.020435664802789688\n",
      " train_psnr                ==> 16.98810386657715\n",
      " train_ssim                ==> 0.5238020420074463\n",
      " val_loss                  ==> 0.00882625942613231\n",
      " val_psnr                  ==> 23.05238914489746\n",
      " val_ssim                  ==> 0.7012674808502197\n",
      "Model weights saved to: ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "Best model weights w/ val loss 0.008826 saved to ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "------------------------------------------------------------\n",
      "                    E P O C H   15/30                    \n",
      "------------------------------------------------------------\n",
      " Runtime                   ==> 161.26126098632812s\n",
      " Learning rate             ==>      9e-05\n",
      " train_loss                ==> 0.015173680149018764\n",
      " train_psnr                ==> 18.457427978515625\n",
      " train_ssim                ==> 0.562584400177002\n",
      " val_loss                  ==> 0.00901483496709261\n",
      " val_psnr                  ==> 22.62440299987793\n",
      " val_ssim                  ==> 0.7024723291397095\n",
      "------------------------------------------------------------\n",
      "                    E P O C H   16/30                    \n",
      "------------------------------------------------------------\n",
      " Runtime                   ==> 162.39812207221985s\n",
      " Learning rate             ==>      9e-05\n",
      " train_loss                ==> 0.016968362033367157\n",
      " train_psnr                ==> 18.01507568359375\n",
      " train_ssim                ==> 0.5573650598526001\n",
      " val_loss                  ==> 0.008700423208938445\n",
      " val_psnr                  ==> 23.141990661621094\n",
      " val_ssim                  ==> 0.7048922181129456\n",
      "Model weights saved to: ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "Best model weights w/ val loss 0.008700 saved to ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "------------------------------------------------------------\n",
      "                    E P O C H   17/30                    \n",
      "------------------------------------------------------------\n",
      " Runtime                   ==> 161.8097529411316s\n",
      " Learning rate             ==>      9e-05\n",
      " train_loss                ==> 0.007746098563075066\n",
      " train_psnr                ==> 21.269195556640625\n",
      " train_ssim                ==> 0.7069506645202637\n",
      " val_loss                  ==> 0.008616958544007503\n",
      " val_psnr                  ==> 23.305437088012695\n",
      " val_ssim                  ==> 0.7072799801826477\n",
      "Model weights saved to: ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "Best model weights w/ val loss 0.008617 saved to ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "                    E P O C H   18/30                    \n",
      "------------------------------------------------------------\n",
      " Runtime                   ==> 161.9854109287262s\n",
      " Learning rate             ==>      9e-05\n",
      " train_loss                ==> 0.018706731498241425\n",
      " train_psnr                ==> 17.576303482055664\n",
      " train_ssim                ==> 0.5368340015411377\n",
      " val_loss                  ==> 0.008601872308645397\n",
      " val_psnr                  ==> 23.255788803100586\n",
      " val_ssim                  ==> 0.7084715366363525\n",
      "Model weights saved to: ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n",
      "Best model weights w/ val loss 0.008602 saved to ./Models/SRCNN/Conv-7_Flt-56-16-16-16-16-16-56_Krnl-55-11-33-33-33-33-11_Strd-11-11-11-11-11-11-11-Deconv-1_Flt-3_Krnl-88_Strd-44_Unknown_x4/\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "if ui.yes_no_menu('Train model (y/n) ? '):\n",
    "    \n",
    "    epochs = int(input('Number of epochs to run: '))\n",
    "\n",
    "    print('Training: \\n{}'.format(model.model.name))\n",
    "    model.train(total_epochs    = epochs,\n",
    "                steps_per_epoch = 200,\n",
    "                batch_size      = batch_size,\n",
    "                datahandler     = datahandler,\n",
    "                validation_set  = validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-valentine",
   "metadata": {},
   "source": [
    "<a id='evaluate'></a>\n",
    "*Back to [Table of Contents](#toc)*\n",
    "<img src=\"./imgs/evaluate.png\" alt=\"Drawing\" style=\"height: 80px;\"/>\n",
    "# 4. Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-automation",
   "metadata": {},
   "source": [
    "## 4.1 Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-winner",
   "metadata": {},
   "source": [
    "Let's visualise this model's training history, the validation losses are stored in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-reasoning",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(nrows=1,ncols=3,figsize=(16,6),dpi=400)\n",
    "\n",
    "metrics = ['val_loss', 'val_psnr'  , 'val_ssim']\n",
    "names   = ['MSE'     , 'PSNR (dB)' , 'SSIM'    ]\n",
    "\n",
    "for plot,metric,name in zip(ax.ravel(),metrics,names):\n",
    "    plot.plot(model.val_history[metric])\n",
    "    plot.set_title(name)\n",
    "    plot.set_xlabel('Epoch')\n",
    "\n",
    "plt.legend(['Model 1: ' + str(model.model.count_params()) + ' parameters'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-chair",
   "metadata": {},
   "source": [
    "## 4.2 Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-utilization",
   "metadata": {},
   "source": [
    "Now we can verify the performance on the test set, i.e. the 100 validation images of `DIV2K`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-apparel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modules import data_processing as dp\n",
    "from Modules import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-lease",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test = dp.loadImages(directory       = './Datasets/DIV2K_valid_LR_bicubic/X4/',\n",
    "                       file_extension  = '.png',\n",
    "                       loading_message = 'Loading [x4] Bi-Cubic Downsampled Testing Images ')\n",
    "y_test = dp.loadImages(directory       = './Datasets/DIV2K_valid_HR/',\n",
    "                       file_extension  = '.png',\n",
    "                       loading_message = 'Loading High Resolution Testing Images \\t\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-brief",
   "metadata": {},
   "source": [
    "Reshape the images into tensors using our data processing module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = dp.reshapeImgs(x_test)\n",
    "y_test = dp.reshapeImgs(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-blind",
   "metadata": {},
   "source": [
    "Test set is now loaded, I'll create a `pandas` dataframe to hold my evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame() # Create dataframe for the evaluation scores\n",
    "\n",
    "for sample,label in zip(x_test, y_test):\n",
    "    \n",
    "    y_pred  = model.model.predict(sample)               # Predict on the fullsize image\n",
    "    y_pred[y_pred > 1] = 1                              # Constrain predictions to the interval [0,1]\n",
    "    y_pred[y_pred < 0] = 0\n",
    "    scores = metrics.evaluate(y_pred[0], label[0])      # Get a MSE, PSNR and SSIM score dictionary\n",
    "    \n",
    "    results = results.append(scores, ignore_index=True) # Append the score dictionary to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-brush",
   "metadata": {},
   "source": [
    "Now, what's the verdict ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-professional",
   "metadata": {},
   "source": [
    "What are the worst and best predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best prediction was on image:  \\t{}.png\\nWith PSNR score: \\t\\t{:.2f} dB\".format(str(results['PSNR'].idxmax()+801).zfill(4) , results['PSNR'].max()))\n",
    "print(\"Worst prediction was on image: \\t{}.png\\nWith PSNR score: \\t\\t{:.2f} dB\".format(str(results['PSNR'].idxmin()+801).zfill(4) , results['PSNR'].min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-volume",
   "metadata": {},
   "source": [
    "## 4.3 Visual Inspection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-leadership",
   "metadata": {},
   "source": [
    "Now, I've taken aside a couple of $\\times 4$ downscaled image and their `HR` counterparts, to perform some visual inspection of the super-resolved image quality, e.g. if we're seeing checkerboard patterns in the reconstruction etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-cisco",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_no = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-charles",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_img  = dp.loadImages(directory       = './Datasets/Evaluate/' + track + '/'+ scale_str + '/',\n",
    "                          file_extension  = '.png',\n",
    "                          loading_message = 'Loading Test Images ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-threat",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "real_img  = dp.loadImages(directory       = './Datasets/Evaluate/HR/',\n",
    "                          file_extension  = '.png',\n",
    "                          loading_message = 'Loading Ground Truth Images ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor      = dp.reshapeImgs(test_img)\n",
    "pred_tensor      = model.model.predict(test_tensor[img_no])\n",
    "pred_tensor_list = [pred_tensor]\n",
    "pred_img         = dp.reshapeTensor(pred_tensor_list)\n",
    "\n",
    "# Constrain prediction to the [0,1] interval\n",
    "pred_img[0][pred_img[0] > 1] = 1\n",
    "pred_img[0][pred_img[0] < 0] = 0\n",
    "\n",
    "# Make the original image comparable with predicted image, i.e. fit to [0,1] interval\n",
    "real_img[img_no] = real_img[img_no]/255\n",
    "\n",
    "# Evaluate MSE, PSNR and SSIM between the original and super-resolved image\n",
    "image_score = metrics.evaluate(real_img[img_no],pred_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-vulnerability",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(16,5),sharex=True,sharey=True,dpi=400)\n",
    "ax[0].imshow(real_img[img_no])\n",
    "ax[0].set_title('Original')\n",
    "ax[1].imshow(pred_img[0])\n",
    "ax[1].set_title('Reconstruction')\n",
    "plt.suptitle('PSNR: {:.2f} dB | SSIM: {:.2f}'.format(image_score['PSNR'],image_score['SSIM']))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-fossil",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "b,h,w,ch = test_img[img_no].shape\n",
    "test_img[img_no] = np.reshape(test_img[img_no],(h,w,ch))\n",
    "plt.figure(figsize=(16,16),dpi=400)\n",
    "plt.imshow(test_img[img_no])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-vanilla",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16),dpi=400)\n",
    "plt.imshow(pred_img[0])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-pregnancy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16),dpi=400)\n",
    "plt.imshow(real_img[img_no])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-pierre",
   "metadata": {},
   "source": [
    "# <a id='credits'></a>\n",
    "*Back to [Table of Contents](#toc)*\n",
    "<img src=\"./imgs/credits.png\" alt=\"Drawing\" style=\"height: 80px;\"/>\n",
    "# 5. Credits\n",
    "\n",
    "\n",
    "Chapter Title Icons: <a href=\"www.flaticon.com\">Flaticon.com</a>. <br>\n",
    "This notebook has been designed using resources from <a href=\"www.flaticon.com\">Flaticon.com </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
